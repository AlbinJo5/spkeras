{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "##Select GPU 0 or 1\n",
    "GPU_INDEX = 1\n",
    "GPU_MEM = 0.95\n",
    "###GPU Configuration\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpu = '/gpu:'+ str(GPU_INDEX)\n",
    "###Set Memory limit (DO NOT OVER 5G!!!)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[GPU_INDEX], \n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=GPU_MEM*10*1024)])\n",
    "##WARNING!!!\n",
    "'''You have to put some critical codes (e.g. Create ANN and fit)  \n",
    "    inside the with statement(e.g. with tf.device(gpu):)!!!''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spkeras.models import cnn_to_snn\n",
    "from spkeras.utils import save_pickle, load_pickle\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "with tf.device(gpu):\n",
    "    cnn_mdl = load_model('cifar10vgg_bn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4384 - accuracy: 0.9276\n",
      "{'timesteps': 256, 'thresholding': 0.5, 'amp_factor': 100000, 'signed_bit': 0, 'spike_ext': 0, 'use_bias': True, 'scaling_factor': 1, 'method': 0}\n",
      "Start Converting...\n",
      "Extracting Lambda...\n",
      "2/60Activation\n",
      "6/60Activation\n",
      "7/60AveragePooling2D\n",
      "10/60Activation\n",
      "14/60Activation\n",
      "15/60AveragePooling2D\n",
      "18/60Activation\n",
      "22/60Activation\n",
      "26/60Activation\n",
      "27/60AveragePooling2D\n",
      "30/60Activation\n",
      "34/60Activation\n",
      "38/60Activation\n",
      "39/60AveragePooling2D\n",
      "42/60Activation\n",
      "46/60Activation\n",
      "50/60Activation\n",
      "51/60AveragePooling2D\n",
      "56/60Activation\n",
      "59/60Activation\n",
      "maximum activations: [1.0, 29.562387, 38.42166, 17.9191, 13.923333, 19.42382, 11.905245, 8.916558, 13.712846, 13.780908, 8.165588, 12.632113, 13.6503315, 13.902915, 9.4377165, 8.193663, 6.443161, 5.4482145, 4.2760696, 2.4774842, 19.505877]\n",
      "Building new model...\n",
      "spikeforward_0_threshold: 2956238.7466430664\n",
      "spikeforward_1_threshold: 129968.05965209183\n",
      "spikeforward_2_threshold: 0.46638015\n",
      "spikeforward_3_threshold: 77701.07492797321\n",
      "spikeforward_4_threshold: 139505.53550069238\n",
      "spikeforward_5_threshold: 0.6129198\n",
      "spikeforward_6_threshold: 74896.05123669108\n",
      "spikeforward_7_threshold: 153790.79453872744\n",
      "spikeforward_8_threshold: 100496.33627909554\n",
      "spikeforward_9_threshold: 0.59252906\n",
      "spikeforward_10_threshold: 154699.36605374294\n",
      "spikeforward_11_threshold: 108060.55173549878\n",
      "spikeforward_12_threshold: 101850.38366119604\n",
      "spikeforward_13_threshold: 0.67883\n",
      "spikeforward_14_threshold: 86818.27492130031\n",
      "spikeforward_15_threshold: 78635.90790995659\n",
      "spikeforward_16_threshold: 84558.10000497325\n",
      "spikeforward_17_threshold: 0.78485703\n",
      "spikeforward_18_threshold: 57938.350732327875\n",
      "spikeforward_19_threshold: 787325.9629525483\n",
      "New model generated!\n",
      "Changing model timesteps...\n",
      "New model generated!\n",
      "{'timesteps': 256, 'thresholding': 0, 'amp_factor': 100000, 'signed_bit': 0, 'spike_ext': 0, 'use_bias': True, 'scaling_factor': 1, 'method': 0}\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 13590839296.0000 - accuracy: 0.9241\n",
      "Changing model timesteps...\n",
      "New model generated!\n",
      "{'timesteps': 256, 'thresholding': 0.5, 'amp_factor': 100000, 'signed_bit': 0, 'spike_ext': 0, 'use_bias': True, 'scaling_factor': 1, 'method': 0}\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 13590839296.0000 - accuracy: 0.9266\n"
     ]
    }
   ],
   "source": [
    "timesteps = [256]\n",
    "\n",
    "thresholding = [0,0.5]\n",
    "scaling_factor = [1]\n",
    "\n",
    "with tf.device(gpu):\n",
    "    cnn_result = []\n",
    "    snn_result = []\n",
    "\n",
    "    _, cnn_acc = cnn_mdl.evaluate(x_test,y_test)\n",
    "    snn_mdl = cnn_to_snn(amp_factor=100000,method=0)(cnn_mdl,x_train)\n",
    "    \n",
    "    result = []\n",
    "    for s1 in thresholding:\n",
    "        _result = []\n",
    "        for s2 in scaling_factor:\n",
    "            __result = []\n",
    "            for t in timesteps:\n",
    "                _,acc = snn_mdl.evaluate(x_test,y_test,timesteps=t,\n",
    "                                            thresholding=s1,                                        \n",
    "                                            scaling_factor=s2)\n",
    "                __result.append(acc)\n",
    "            _result.append(__result)\n",
    "            \n",
    "        result.append(_result)\n",
    "        \n",
    "    cnn_result.append(cnn_acc)\n",
    "    snn_result.append(result)   \n",
    "                 \n",
    "        \n",
    "#    save_pickle(snn_result,'mdl_bn'+'_snn_result','../result/')\n",
    "#    save_pickle(cnn_result,'mdl_bn'+'_cnn_result','../result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(gpu):\n",
    "    snn_mdl.evaluate(x_test,y_test,timesteps=256,scaling_factor=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [16,32,48,64,80,96,112,128,144,160,176,192,208,224,240,256]\n",
    "\n",
    "thresholding = [0,0.5]\n",
    "scaling_factor = [1]\n",
    "\n",
    "with tf.device(gpu):\n",
    "    cnn_result = []\n",
    "    snn_result = []\n",
    "\n",
    "    _, cnn_acc = cnn_mdl.evaluate(x_test,y_test)\n",
    "    snn_mdl = cnn_to_snn(method=0)(cnn_mdl,x_train)\n",
    "    \n",
    "    result = []\n",
    "    for s1 in thresholding:\n",
    "        _result = []\n",
    "        for s2 in scaling_factor:\n",
    "            __result = []\n",
    "            for t in timesteps:\n",
    "                _,acc = snn_mdl.evaluate(x_test,y_test,timesteps=t,\n",
    "                                            thresholding=s1,                                        \n",
    "                                            scaling_factor=s2)\n",
    "                __result.append(acc)\n",
    "            _result.append(__result)\n",
    "            \n",
    "        result.append(_result)\n",
    "        \n",
    "    cnn_result.append(cnn_acc)\n",
    "    snn_result.append(result)   \n",
    "                 \n",
    "        \n",
    "    save_pickle(snn_result,'mdl_bn'+'_snn_result','../result/')\n",
    "    save_pickle(cnn_result,'mdl_bn'+'_cnn_result','../result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [16,32,48,64,80,96,112,128,144,160,176,192,208,224,240,256]\n",
    "thresholding = [0.5]\n",
    "scaling_factor = [1]\n",
    "bit = [7,8,9,10]\n",
    "\n",
    "with tf.device(gpu):\n",
    "#with mirrored_strategy.scope():\n",
    "    cnn_result = []\n",
    "    snn_result = []\n",
    "\n",
    "    _, cnn_acc = cnn_mdl.evaluate(x_test,y_test)\n",
    "    cnn_result.append(cnn_acc)\n",
    "    result_=[]\n",
    "    for b in bit:\n",
    "        snn_mdl = cnn_to_snn(signed_bit=b)(cnn_mdl,x_train)\n",
    "        \n",
    "        result = []\n",
    "        for s1 in thresholding:\n",
    "            _result = []\n",
    "            for s2 in scaling_factor:\n",
    "                __result = []\n",
    "                for t in timesteps:\n",
    "                    _,acc = snn_mdl.evaluate(x_test,y_test,timesteps=t,\n",
    "                                                thresholding=s1,                                        \n",
    "                                                scaling_factor=s2,\n",
    "                                                spike_ext=0)\n",
    "                    __result.append(acc)\n",
    "                _result.append(__result)\n",
    "                \n",
    "            result.append(_result)\n",
    "        result_.append(result)\n",
    "            \n",
    "    snn_result.append(result_)   \n",
    "                 \n",
    "        \n",
    "    save_pickle(snn_result,'mdl_bn_bit'+'_snn_result','../result/')\n",
    "    save_pickle(cnn_result,'mdl_bn_bit'+'_cnn_result','../result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [16,32,48,64,80,96,112,128,144,160,176,192,208,224,240,256]\n",
    "\n",
    "thresholding = [0,0.5]\n",
    "scaling_factor = [1]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "with tf.device(gpu):\n",
    "    cnn_result = []\n",
    "    snn_result = []\n",
    "    snn_result_ = []\n",
    "    \n",
    "    _, cnn_acc = cnn_mdl.evaluate(x_test,y_test)\n",
    "    snn_mdl = cnn_to_snn()(cnn_mdl,x_train)\n",
    "    \n",
    "    result = []\n",
    "    result_ = []\n",
    "    shape,Neuros = snn_mdl.NeuronNumbers(mode=1)\n",
    "\n",
    "    for s1 in thresholding:\n",
    "        _result = []\n",
    "        _result_ = []\n",
    "        for s2 in scaling_factor:\n",
    "            __result = []\n",
    "            __result_ = []\n",
    "            for t in timesteps:\n",
    "                l,N = snn_mdl.SpikeCounter(x_train,timesteps=t,\n",
    "                                            thresholding=s1,                                        \n",
    "                                            scaling_factor=s2)\n",
    "                #Count operations \n",
    "                inp_spikes = x_train*t\n",
    "                inp_spikes = np.floor(inp_spikes)\n",
    "                inp_spikes = (np.sum(inp_spikes)/np.prod(x_train.shape))*np.prod(shape[0])\n",
    "                inp_spikes = np.ceil(inp_spikes)\n",
    "                \n",
    "                a = []\n",
    "                for k in range(len(Neuros)):\n",
    "                    if k == len(Neuros) - 1:\n",
    "                        continue\n",
    "                    _a = N[k]/Neuros[k]*np.prod(shape[k+1])\n",
    "                    a.append(_a)\n",
    "                    \n",
    "                __result_.append(np.max(l))\n",
    "                __result.append(np.floor(np.sum(a+inp_spikes)))\n",
    "            _result.append(__result)\n",
    "            _result_.append(__result_)\n",
    "        result.append(_result)\n",
    "        result_.append(_result_)\n",
    "        \n",
    "    snn_result.append(result) \n",
    "    snn_result_.append(result)\n",
    "                 \n",
    "    save_pickle(snn_result,'mdl_bn_spikes'+'_snn_result','../result/')\n",
    "    save_pickle(snn_result_,'mdl_bn_max_train'+'_snn_result','../result/')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
